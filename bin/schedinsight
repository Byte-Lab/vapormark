#!/usr/bin/env python3
import os
import sys
import argparse
import csv
import zlib
import collections
import statistics
import datetime
import subprocess
import pickle
import numpy as np
import matplotlib.pyplot as plt
import pdb

def hash_rgb_from_str(s):
    h = zlib.crc32( bytes(s, 'utf-8') )
    r = (h & 0x00FF00) >> 8
    g = (h & 0xFF0000) >> 16
    b = (h & 0x0000FF) >> 0
    return (float(r)/0xFF, float(g)/0xFF, float(b)/0xFF)

def median(l):
    if len(l) == 0:
        return 0.0
    return statistics.median(l)

def average(l):
    if len(l) == 0:
        return 0.0
    return statistics.mean(l)

def aad(l, avg):
    # aad (average absolute deviation)
    # https://en.wikipedia.org/wiki/Average_absolute_deviation
    if len(l) == 0:
        return 0.0
    sum = 0.0
    for v in l:
        sum = sum + abs(avg - v)
    return sum / len(l)

class ev_type:
    SCHED = 0
    IDLE  = 1
    MIG   = 2
    AWAKE = 3

class ev_time:
    time   = 0.0 
    cpu_id = 0

    def __init__(self, t, c):
        self.time = t
        self.cpu_id = c

    def __repr__(self):
        return "\t".join(["%.6f" % self.time, "[%d]" % self.cpu_id])

class task_stat:
    # task
    task = None

    # ev_sched or ev_idle stat
    sched_num = 0

    sched_waits = None
    sched_wait_med = 0.0
    sched_wait_avg = 0.0
    sched_wait_aad = 0.0
    sched_wait_sum = 0.0

    sched_delays = None
    sched_delay_med = 0.0
    sched_delay_avg = 0.0
    sched_delay_aad = 0.0
    sched_delay_sum = 0.0

    sched_runs = None
    sched_run_med = 0.0
    sched_run_avg = 0.0
    sched_run_aad = 0.0
    sched_run_sum = 0.0
    # TODO: sched_ideal_runs = []

    # ev_mig stat
    migrated_num = 0

    # TODO: sched reason
    # - iowait
    # - lock_wait
    # - preemption timeout
    # - poll/epoll
    # - pipe read

    def __init__(self, task):
        self.task = task
        self.sched_num = 0
        self.sched_waits = []
        self.sched_wait_med = 0.0
        self.sched_wait_avg = 0.0
        self.sched_wait_aad = 0.0
        self.sched_wait_sum = 0.0

        self.sched_delays = []
        self.sched_delay_med = 0.0
        self.sched_delay_avg = 0.0
        self.sched_delay_aad = 0.0
        self.sched_delay_sum = 0.0

        self.sched_runs = []
        self.sched_run_med = 0.0
        self.sched_run_avg = 0.0
        self.sched_run_aad = 0.0
        self.sched_run_sum = 0.0

        self.migrated_num = 0

    def analyze_stat(self):
        # ev_sched or ev_idle?
        if self.task.is_idle() == True:
            sched_events = self.task.ctask_ty_events.get(ev_type.IDLE, collections.OrderedDict()) 
        else:
            sched_events = self.task.ctask_ty_events.get(ev_type.SCHED, collections.OrderedDict())

        for time, ev in sched_events.items():
            self.sched_waits.append(ev.period.wait_time)
            self.sched_delays.append(ev.period.sch_delay)
            self.sched_runs.append(ev.period.run_time)

        # ev_sched/ev_idle stat
        self.sched_num = len(sched_events)

        self.sched_wait_med = median(self.sched_waits)
        self.sched_wait_avg = average(self.sched_waits)
        self.sched_wait_aad = aad(self.sched_waits, self.sched_wait_avg)
        self.sched_wait_sum = sum(self.sched_waits)

        self.sched_delay_med = median(self.sched_delays)
        self.sched_delay_avg = average(self.sched_delays)
        self.sched_delay_aad = aad(self.sched_delays, self.sched_delay_avg)
        self.sched_delay_sum = sum(self.sched_delays)

        self.sched_run_med = median(self.sched_runs)
        self.sched_run_avg = average(self.sched_runs)
        self.sched_run_aad = aad(self.sched_runs, self.sched_run_avg)
        self.sched_run_sum = sum(self.sched_runs)

        # ev_mig stat
        migrated_events = self.task.ctask_ty_events.get(ev_type.MIG, collections.OrderedDict()) 
        self.migrated_num = len(migrated_events)

  
class ev_task:
    # per-class variables
    task_dict = {} 
    idle_task_name = "<idle>[0/0]"

    # per-instanace variables
    task_name = ""
    task_id   = 0
    parent_id = 0
    color = (0.0, 0.0, 0.0)

    # task indexes to events
    ctask_ty_events  = None  # cur_task:ty   -> [events]
    ctask_cs_events  = None  # cur_task:cs   -> [events]
    ctask_cst_events = None  # cur_task:cst  -> [events]
    ntask_ty_events  = None  # next_task:ty  -> [events]

    # task stat
    task_stat = None

    def __init__(self, tname, tid, pid):
        self.task_name = tname
        self.task_id = tid
        self.parent_id = pid
        self.color = hash_rgb_from_str( str(self) )

        self.ctask_ty_events  = collections.OrderedDict()
        self.ctask_cs_events  = collections.OrderedDict()
        self.ctask_cst_events = collections.OrderedDict()
        self.ntask_ty_events  = collections.OrderedDict()

        self.task_stat = task_stat(self)

    def __repr__(self):
        return "%s[%d/%d]" % (self.task_name, self.task_id, self.parent_id)

    @classmethod
    def get_instance(cls, tname, tid, pid):
        key = "%s[%d/%d]" % (tname, tid, pid)
        inst = cls.task_dict.get(key)
        if inst == None: 
            inst = cls(tname, tid, pid)
            cls.task_dict[key] = inst
        return inst

    @classmethod
    def find(cls, task_name):
        return cls.task_dict.get(task_name, None)

    @classmethod
    def analyze_stat(cls):
        for k, t in cls.task_dict.items():
            t.task_stat.analyze_stat()

    def is_idle(self):
        if self.task_id == 0 and self.parent_id == 0 and self.task_name == "<idle>":
            return True
        return False

    def link_ctask(self, ev, cs = None):
        # - cur_task:ty -> [events]
        ty_events = self.ctask_ty_events.get(ev.ty)
        if ty_events == None:
            ty_events = self.ctask_ty_events[ev.ty] = collections.OrderedDict()
        ty_events[ev.time.time] = ev

        if cs == None:
            return
        # - cur_task:cs -> [events]
        cs_events = self.ctask_cs_events.get(cs)
        if cs_events == None:
            cs_events = self.ctask_cs_events[cs] = collections.OrderedDict()
        cs_events[ev.time.time] = ev
        # - cur_task:cst -> [events]
        cst = cs.cs_type
        cst_events = self.ctask_cst_events.get(cst)
        if cst_events == None:
            cst_events = self.ctask_cst_events[cst] = collections.OrderedDict()
        cst_events[ev.time.time] = ev
        # - cs -> {ctasks}
        cs.link_ctask(self)

    def link_ntask(self, ev, cs = None):
        # - next_task:ty -> [events]
        ty_events = self.ntask_ty_events.get(ev.ty)
        if ty_events == None:
            ty_events = self.ntask_ty_events[ev.ty] = collections.OrderedDict()
        self.ntask_ty_events[ev.time.time] = ev

class ev_period:
    wait_time = 0.0
    sch_delay = 0.0
    run_time  = 0.0

    def __init__(self, w, s, r):
        self.wait_time = w
        self.sch_delay = s
        self.run_time  = r

    def __repr__(self):
        return "\t".join(["%.3f" % self.wait_time, 
                          "%.3f" % self.sch_delay,
                          "%.3f" % self.run_time])

class callstack_stat:
    # callstack
    callstack = None

    # callstack stats
    num_ctask = 0
    num_sched_events = 0

    def __init__(self, cs):
        self.callstack = cs
        self.num_sched_events = 0

    def analyze_stat(self):
        self.num_ctask = len(self.callstack.cs_ctasks)
        self.num_sched_events = 0
        for ctask in self.callstack.cs_ctasks:
            self.num_sched_events = self.num_sched_events + len(ctask.ctask_cs_events)

class callstack_type:
    type_dict = None

    @classmethod
    def init(cls):
        if cls.type_dict != None:
            return
        # dictionary for the know callsites
        d = [
                # wait for events
                ("epoll_", "epoll"),
                ("sys_poll", "poll"),
                ("sys_select", "select"),
                ("sys_pselect", "pselect"),
                # pipe IO
                ("pipe_read", "pipe_read"),
                ("pipe_write", "pipe_write"),
                # futex
                ("futex_wake", "futex_wake"),
                ("futex_wait", "futex_wait"),
                ("sys_futex", "futex"),
                ("futex_", "futex"),
                # lock
                ("up_read", "unlock"),
                ("down_read", "lock"),
                ("up_write", "unlock"),
                ("down_write", "lock"),
                ("_unlock", "unlock"),
                ("_lock", "lock"),
                # file IO
                ("vfs_read", "vfs_read"),
                ("vfs_write", "vfs_write"),
                ("sys_read", "sys_read"),
                ("sys_write", "sys_write"),
                ("sys_ioctl", "ioctl"),
                ("io_schedule", "io_schedule"),
                ("page_fault", "page_fault"),
                # network IO
                ("sys_recvmsg", "recvmsg"),
                ("sys_recvfrom", "recvfrom"),
                ("sys_sendto", "sendto"),
                # system call
                ("sys_clone", "clone"),
                ("ret_from_fork", "fork"),
                ("do_exit", "exit"),
                ("do_wait", "wait"),
                ("sys_sched_yield", "yield"),
                ("do_nanosleep", "sleep"),
                ("sys_clock_nanosleep", "sleep"),
                ("usleep", "sleep"),
                ("syscall_", "syscall"),
                ("syscall_", "syscall"),
                # memory
                ("do_mprotect", "mprotect"),
                ("do_mmap", "mmap"),
                ("kmem_cache_alloc", "alloc"),
                ("vmalloc", "alloc"),
                ("kmalloc", "alloc"),
                # sched preemption
                ("asm_sysvec_apic_timer_interrupt", "sched_preempt"),
                ("asm_sysvec_reschedule_ipi", "sched_preempt"),
                ("schedule_preempt_disabled", "sched_preempt"),
                ("preempt_schedule", "sched_preempt"),
                # sched wait
                ("schedule_timeout", "sched_wait"),
                ("wait_for_completion", "sched_wait"),
                # others
                ("try_to_wake_up", "try_to_wake_up"),
                ("asm_common_interrupt", "hw_interrupt"),
                ]
        cls.type_dict = d 

    @classmethod
    def get_type(cls, cs):
        if cls.type_dict == None:
            cls.init()
        for k, t in cls.type_dict:
            if cs.find(k) != -1:
                return t
        return "[unknown]" # + cs


class ev_callstack:
    # per-class variables
    cs_dict = {} 
    cst_dict = {}

    # per-instanace variables
    cs  = ""
    cs_type = ""
    color = (0.0, 0.0, 0.0)

    # callstack to caller tasks
    cs_ctasks = None

    # callstack stat
    callstack_stat = None

    @classmethod
    def get_instance(cls, cs):
        inst = cls.cs_dict.get(cs)
        if inst == None: 
            # create an instance
            inst = cls(cs)
            # add it to the cs_dict
            cls.cs_dict[cs] = inst
            # add it to the cst_dict
            cst_set = cls.cst_dict.get(inst.cs_type)
            if cst_set == None: 
                cst_set = cls.cst_dict[inst.cs_type] = set()
            cst_set.add(inst)
        return inst

    @classmethod
    def find(cls, cs):
        return cls.cs_dict.get(cs, None)

    @classmethod
    def analyze_stat(cls):
        for k, cs in cls.cs_dict.items():
            cs.callstack_stat.analyze_stat()

    def link_ctask(self, ctask):
        self.cs_ctasks.add(ctask)

    def link_ntask(self, ntask):
        self.cs_ntasks.add(ntask)

    def __init__(self, cs):
        self.cs = cs
        self.cs_type = callstack_type.get_type(cs)
        self.color = hash_rgb_from_str( str(self) )
        self.cs_ctasks = set()
        self.callstack_stat = callstack_stat(self)

    def __repr__(self):
        return self.cs

class ev_sched:
    # per-class variables
    ty = ev_type.SCHED
    color =  hash_rgb_from_str( str(ev_type.SCHED) )

    # per-instanace variables
    time   = None
    period = None
    cur_task  = None
    next_task = None 
    callstack = None

    def __init__(self, time, period, cur_task, next_task, callstack):
        self.time = time
        self.period = period

        self.cur_task = cur_task
        self.callstack = callstack
        self.next_task = next_task

        self.cur_task.link_ctask(self, self.callstack)
        self.next_task.link_ntask(self, self.callstack)

    def __repr__(self):
        return "\t".join(["S", str(self.time), str(self.cur_task), str(self.period), 
                          "=>", str(self.next_task), str(self.callstack)])

class ev_idle:
    # per-class variables
    ty = ev_type.IDLE
    color =  hash_rgb_from_str( str(ev_type.IDLE) )

    # per-instanace variables
    time = None
    period = None
    cur_task  = None
    next_task = None 

    def __init__(self, time, period, cur_task, next_task):
        self.time = time
        self.period = period

        self.cur_task = cur_task
        self.next_task = next_task

        self.cur_task.link_ctask(self)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["I", str(self.time), str(self.cur_task), str(self.period), 
                          "=>", str(self.next_task)])

class ev_mig:
    # per-class variables
    ty = ev_type.MIG
    color =  hash_rgb_from_str( str(ev_type.MIG) )

    # per-instanace variables
    time   = None
    cur_task  = None
    next_task = None 
    to_cpu_id = 0

    def __init__(self, time, cur_task, migrated_task, to_cpu_id):
        self.time = time
        self.to_cpu_id = to_cpu_id

        self.cur_task = migrated_task # migrated task should be the key
        self.next_task = cur_task     # next task is indeed an initiator

        self.cur_task.link_ctask(self)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["M", str(self.time), str(self.cur_task), 
                          "=>", str(self.next_task)])

class ev_awake:
    # per-class variables
    ty = ev_type.AWAKE
    color =  hash_rgb_from_str( str(ev_type.AWAKE) )

    # per-instanace variables
    time   = None
    cur_task  = None
    next_task = None 

    def __init__(self, time, cur_task, awakened_task):
        self.time = time

        self.cur_task = awakened_task # awakened task should be the key
        self.next_task = cur_task     # next task is indeed an initiator

        self.cur_task.link_ctask(self)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["A", str(self.time), str(self.cur_task), 
                          "=>", str(self.next_task)])

class pearson_corr:
    x_label = ""
    y_label = ""
    data_label = ""
    x_data  = None
    y_data  = None
    data_names = None
    pcc     = None

    def __init__(self, x, y, d):
        self.x_label = x
        self.y_label = y
        self.data_label = d
        self.x_data  = None
        self.y_data  = None
        self.data_names = None
        self.pcc     = None

class analysis_results:
    # task & idle status
    task_stat_names = None
    task_stats = None
    idle_stats = None
    task_stat_formats = None

    # pearson correlations
    corrs = None

    # callstack 
    cs_stat_names = None
    cs_stats = None
    cs_stat_formats = None

    # callstack types
    cst_stat_names = None
    cst_stats = None
    cst_stat_formats = None

    def __init__(self):
        # task & idle status
        self.task_stat_names = []
        self.task_stats = []
        self.idle_stats = []
        self.task_stat_formats = []
        # pearson correlations
        self.corrs = []
        # callstack 
        self.cs_stat_names = []
        self.cs_stats = []
        self.cs_stat_formats = []
        # callstack types
        self.cst_stat_names = []
        self.cst_stats = []
        self.cst_stat_formats = []

class pickled_jar:
    task_dict = None
    cs_dict = None
    sched_events = None

    def __init__(self, se):
        self.task_dict = ev_task.task_dict
        self.cs_dict = ev_callstack.cs_dict
        self.sched_events = se


def parse_ev_time(toks):
    time = float(toks[0])
    cpu_id = int(toks[1][1:-1])
    return ev_time(time, cpu_id), toks[2:]
    
def parse_ev_type(toks):
    if toks[0] == "s":
        return ev_type.SCHED, toks[1:]
    elif toks[0] == "i":
        return ev_type.IDLE, toks[1:]
    elif toks[0] == "m":
        return ev_type.MIG, toks[1:]
    else:
        return ev_type.AWAKE, toks

def parse_ev_task(toks):
    if toks[0] == "<idle>" or toks[0] == "swapper": 
        return ev_task.get_instance(toks[0], 0, 0), toks[1:]
    
    tstr = ""
    for i, t in enumerate(toks):
        if t[-1] == "]":
            tstr = tstr + t
            toks = toks[i+1:]
            break
        tstr = tstr + t + " "

    tsk_tok = tstr[:-1].split("[")
    tname = tsk_tok[0]
    tid, pid = 0, 0
    if len(tsk_tok) == 2:
        pid_tok = tsk_tok[1].split("/")
        tid = int(pid_tok[0])
        if len(pid_tok) == 2: 
            pid = int(pid_tok[1])
    return ev_task.get_instance(tname, tid, pid), toks

def parse_ev_period(toks):
    w = float(toks[0])
    s = float(toks[1])
    r = float(toks[2])
    return ev_period(w, s, r), toks[3:]

def parse_ev_callstack(toks):
    cs = ' '.join(toks)
    return ev_callstack.get_instance(cs), []

def parse_ev_sched(toks, time):
    cur_task, toks = parse_ev_task(toks)
    period, toks = parse_ev_period(toks)
    next_task, toks = parse_ev_task(toks[1:]) # toks[0] should be 'next:'
    callstack, toks = parse_ev_callstack(toks)
    return ev_sched(time, period, cur_task, next_task, callstack)

def parse_ev_idle(toks, time):
    cur_task, toks = parse_ev_task(toks)
    period, toks = parse_ev_period(toks) 
    next_task, toks = parse_ev_task(toks[1:]) # toks[0] should be 'next:'
    return ev_idle(time, period, cur_task, next_task)

def parse_ev_mig(toks, time):
    cur_task, toks = parse_ev_task(toks)
    migrated_task, toks = parse_ev_task(toks[1:])  # toks[0] should be "migrated:"
    to_cpu_id = int(toks[3]) # toks[] = ["cpu", from_cpu_id, "=>", to_cpu_id]
    return ev_mig(time, cur_task, migrated_task, to_cpu_id)

def parse_ev_awake(toks, time):
    cur_task, toks = parse_ev_task(toks)
    awakened_task, toks = parse_ev_task(toks[1:])  # toks[0] should be "awakened:"
    return ev_awake(time, cur_task, awakened_task)

def parse_ev_line(line):
    parsers = {ev_type.SCHED: parse_ev_sched, ev_type.IDLE: parse_ev_idle, 
               ev_type.MIG: parse_ev_mig,     ev_type.AWAKE: parse_ev_awake,}

    toks = line.split()
    if len(toks) == 0:
        return None

    time, toks = parse_ev_time(toks)
    ty, toks = parse_ev_type(toks)
    return parsers[ty](toks, time)

def skip_column_header(f):
    f.readline()
    f.readline()
    f.readline()

def get_schedmon_log_name(args, kind):
    log = os.path.join(args.outdir,
                       args.log + "-schedmon-" + kind+ "__.log")
    return log

def parse_sched_events(f):
    # - header
    skip_column_header(f)

    # - scheduling events
    events = collections.OrderedDict()
    for line in f:
        ev = parse_ev_line(line)
        if ev == None:
            break
        events[ev.time.time] = ev
    return events

def is_newer(file_new, file_old):
    if os.path.isfile(file_new) == False:
        return False
    return os.path.getmtime(file_new) > os.path.getmtime(file_old)

def load_pickle(args, log_fil):
    if args.pickle == False:
        return None

    pickle_fil = get_outfile_name(args, "pickled_jar__", "pickle")
    if is_newer(pickle_fil, log_fil):
        with open(pickle_fil, mode="rb") as pf:
            pj = pickle.load(pf)
            # init class variables
            ev_task.task_dict = pj.task_dict
            ev_callstack.cs_dict = pj.cs_dict
            return pj.sched_events
    return None

def save_pickle(args, sched_events):
    if args.pickle == False:
        return

    pickle_fil = get_outfile_name(args, "pickled_jar__", "pickle")
    pj = pickled_jar(sched_events)
    with open(pickle_fil, mode="wb") as f:
        pickle.dump(pj, f)

def parse_schedmon_timehist(args):
    # get a log file name
    log_fil = get_schedmon_log_name(args, "timehist_full")
    if os.path.isfile(log_fil) == False:
        log_fil = get_schedmon_log_name(args, "timehist_short")

    # first try to load the pickled events
    sched_events = load_pickle(args, log_fil)
    if sched_events != None:
        return  sched_events

    # if nothing pickled, parse the log and pickle it
    with open(log_fil, "r") as f:
        # try to load the pickled log first
        sched_events = load_pickle(args, log_fil)

        # parse and pickle the log
        if sched_events == None:
            sched_events = parse_sched_events(f)
            save_pickle(args, sched_events)
        # - TODO: Runtime summary
        # - TODO: Terminated tasks:
        # - TODO: Idle stats:
        # - TODO: Overall smmary
    return sched_events

def load_schedmon_timehist(args):
    return parse_schedmon_timehist(args)

def filter_sched_events(events, filter_fn, filter_data):
    filtered_events = collections.OrderedDict()

    for time, ev in events.items():
        if filter_fn(ev, filter_data) == True:
            filtered_events[time] = ev
    rebuild_indexes(filtered_events)

    return filtered_events

def is_meaningful_task(args, task_stat):
    # filter out statically meaningless tasks
    if task_stat.sched_num < args.minsched:
        return False
    # filter out never scheduled tasks
    if task_stat.sched_num == 0 and task_stat.migrated_num == 0:
        return False
    return True


def analyze_task_idle_stat(args, r):
    stat_names = ["task_name", "num_sched", "num_mig", # 0--2
                  "wait_time_med", "wait_time_avg",
                  "wait_time_aad", "wait_time_total", # 3--6
                  "sched_delay_med", "sched_delay_avg",
                  "sched_delay_aad", "sched_delay_total", # 7-10
                  "runtime_med", "runtime_avg",
                  "runtime_aad", "runtime_total", # 11-14
                  "rank_nsched", "rank_nmig", "rank_runtime", "score", # 15-18
                  ]

    # per-task stats 
    ev_task.analyze_stat()

    # collect system-wide task stats
    task_stats = []
    idle_stats = []
    for k, t in ev_task.task_dict.items():
        s = t.task_stat

        # filter out statically meaningless tasks
        if is_meaningful_task(args, s) == False:
            continue

        t_info = [str(t), s.sched_num, s.migrated_num]
        w_stat = [s.sched_wait_med, s.sched_wait_avg, s.sched_wait_aad, s.sched_wait_sum]
        d_stat = [s.sched_delay_med, s.sched_delay_avg, s.sched_delay_aad, s.sched_delay_sum]
        r_stat = [s.sched_run_med, s.sched_run_avg, s.sched_run_aad, s.sched_run_sum]

        stat = t_info + w_stat + d_stat + r_stat

        if t.is_idle():
            idle_stats.append(stat + [0, 0, 0, 0])
        else:
            task_stats.append(stat)

    # calc score
    # - by number of sched
    task_stats.sort(reverse = True, key = lambda x: x[1])
    for i, s in enumerate(task_stats):
        s.append(i) # 15
    # - by number of migration
    task_stats.sort(reverse = True, key = lambda x: x[2])
    for i, s in enumerate(task_stats):
        s.append(i) # 16
    # - by total runtime
    task_stats.sort(reverse = True, key = lambda x: x[14])
    for i, s in enumerate(task_stats):
        s.append(i) # 17
    # - score
    for s in task_stats:
        ns, nm, rt = s[15], s[16], s[17]
        score = ns*ns + (rt*rt)/2 + (nm*nm)/8
        s.append(score) #18

    # soft by score
    task_stats.sort(key = lambda x: x[18])

    r.task_stat_names = stat_names
    r.task_stats = task_stats
    r.idle_stats = idle_stats
    r.task_stat_formats = ["{0:^30}"] + ["{0:>14}"] * (len(r.task_stat_names) - 1)

def get_outfile_name(args, kind, suffix):
    ofname = os.path.join(args.outdir, args.log + 
                          "-schedinsight-" + kind + "." + suffix)
    return ofname

def reset_plot():
    plt.clf()
    plt.style.use('default')
    plt.rcParams['font.size'] = 7

def plot_event_chart(args, plot_name, events):
    ty_map = {}
    ctask_map = {}
    ntask_map = {}
    cs_map = {}

    # build data for plot
    def append_color(m, c, i):
        if m.get(c) == None:
            m[c] = []
        m[c].append(i)

    for i, (time, ev) in enumerate(events.items()):
        # - type
        append_color(ty_map, ev.color, i)
        append_color(ctask_map, ev.cur_task.color, i)
        append_color(ntask_map, ev.next_task.color, i)
        if ev.ty == ev_type.SCHED: 
            append_color(cs_map, ev.callstack.color, i)
        # TODO: not very useful if there are more than 1000 events
        # TODO: extend the inerface to time range

    # plot events
    # - prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=4, ncols=1, figsize=(7, 3.5), tight_layout=True)

    # - plot type
    def plot_map(ax, m, title):
        ax.tick_params(left = False, right = False , labelleft = False , 
                       labelbottom = False, bottom = False)
        for c, x_data in m.items():
            ax.bar(x_data, [1] * len(x_data), align='edge', width=1, color = c)
        ax.set_ylim(bottom = 0, top = 1)
        ax.set_ylabel(title)

    plot_map(axs[0], ty_map, "event type")
    plot_map(axs[1], ctask_map, "current task")
    plot_map(axs[2], cs_map, "callstack")
    plot_map(axs[3], ntask_map, "next task")

    # - decoration
    axs[0].tick_params(labeltop = True, top = True)
    axs[3].tick_params(labelbottom = True, bottom = True)
    plt.subplots_adjust(hspace = 0)

    # - save to the file
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)
    plt.close()

def gen_stat_in_csv(col_names, col_formats, tuples, f):
    def get_sep(c, ncol):
        if c == (ncol - 1):
            return "\n"
        else:
            return ", "

    def is_float(n):
        try: 
            return int(n) != float(n)
        except ValueError:
            return False

    # column header
    ncol = len(col_names)
    for i, (fmt, cname) in enumerate(zip(col_formats, col_names)):
        print(fmt.format(cname), end=get_sep(i, ncol), file = f)

    # stat tuples 
    for tup in tuples: 
        for i, (fmt, cdata) in enumerate(zip(col_formats, tup)):
            if is_float(cdata):
                print(fmt.format("%.8f" % cdata), end=get_sep(i, ncol), file = f)
            else:
                print(fmt.format(cdata), end=get_sep(i, ncol), file = f)

def plot_dist_fig(args, plot_name, sorted_values, title, x_label, y_label):
    # prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(3, 8), tight_layout=True)

    # 1) violin plot
    # - plot
    ax = axs[0]
    violin = ax.violinplot([sorted_values], showmeans=True,  quantiles=[0.1, 0.5, 0.9])
    violin['bodies'][0].set_facecolor( hash_rgb_from_str(y_label) )
    violin['cmeans'].set_edgecolor('red')
    # - set title
    ax.set_title(title)
    # - decoration
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)

    # 2) distribution line plot
    # - plot
    ax = axs[1]
    ax.plot(range(len(sorted_values)), sorted_values, linewidth=1, color='black')
    # - decoration
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)

    # 3) histogram plot
    # - plot
    ax = axs[2]
    ax.hist(sorted_values, bins = 30)
    # - decoration
    max_hist = len(sorted_values)/3
    ax.set_ylim(bottom = 0, top = max_hist)
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)

    # - save to the file
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)
    plt.close()

def plot_corr_figs(args, corrs, plot_name):
    # prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=1, ncols=len(corrs), 
                            figsize=(3*len(corrs), 3), tight_layout=True)

    # scatter plot
    for i, corr in enumerate(corrs):
        ax = axs[i]
        colors = []
        for name in corr.data_names:
            colors.append( hash_rgb_from_str(name) )
        ax.scatter(corr.x_data, corr.y_data, c=colors, marker="x")
        ax.set(xlabel=corr.x_label, ylabel=corr.y_label)
        ax.title.set_text("Correlation = " + "{:.2f}".format(corr.pcc[0,1]))

    # - save to the filewineserver
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)
    plt.close()

def transpose_2d_list(ll):
    return list(zip(*ll))

def plot_task_dist_figs(args, stat_names, task_stats):
    stat_cols = transpose_2d_list(task_stats)
    for name, stat in zip(stat_names[1:-4], stat_cols[1:-4]):
        plot_dist_fig(args, "task_dist_" + name, sorted(stat), name, "", "")

def plot_per_task_stat_over_time(args, ts, title, plot_name):
    # prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=6, ncols=1, figsize=(3, 6.5), tight_layout=True)

    def plot_filled_line(ax, data, c, y_label):
        l = len(data)
        ax.fill_between(range(l), data, color = c)
        ax.set_ylabel(y_label)
        ax.tick_params(left = True, right = False, labelleft = True, 
                       labelbottom = False, bottom = False)

    # time serises of wait time, sched delay, and runtimes
    plot_filled_line(axs[0], ts.sched_waits, 
                     ts.task.color, "wait_time:ts")
    plot_filled_line(axs[1], ts.sched_delays, 
                     ts.task.color, "sched_delay:ts")
    plot_filled_line(axs[2], ts.sched_runs, 
                     ts.task.color, "runtime:ts")

    # time serises of wait time, sched delay, and runtimes
    plot_filled_line(axs[3], sorted(ts.sched_waits.copy()), 
                     ts.task.color, "wait_time:dist")
    plot_filled_line(axs[4], sorted(ts.sched_delays.copy()), 
                     ts.task.color, "sched_delay:dist")
    plot_filled_line(axs[5], sorted(ts.sched_runs.copy()), 
                     ts.task.color, "runtime:dist")

    # decoration
    axs[0].set_title(title)
    axs[0].tick_params(labeltop = True, top = True)
    axs[5].tick_params(labelbottom = True, bottom = True)
    plt.subplots_adjust(hspace = 0)

    # save to the file
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)
    plt.close()

def plot_pie_chart(args, name_list, cnt_list, plot_name):
    # prep data
    total_cnt = sum(cnt_list)
    label_list = list( map(lambda t: "%s (%.2f%s)" % (t[0], t[1] / total_cnt, "%"), 
                           zip(name_list, cnt_list)) )
    rgb_list = list( map(lambda s: hash_rgb_from_str(s), name_list) )

    # prepare canvas
    reset_plot()
    plt.rcParams['font.size'] = 10
    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 13))

    # plot
    ax.pie(cnt_list, labels=label_list, colors=rgb_list)

    # save fig
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)
    plt.close()

def get_res_path(args, fname):
    afil = os.path.join(args.outdir, fname)
    rfil = os.path.relpath(afil, start = args.outdir)
    return afil, rfil

def gen_md_title(title, f):
    print("``` {=html}", file = f)
    print("<style>", file = f)
    print("body { min-width: 80% !important; }", file = f)
    print("</style>", file = f)
    print("```", file = f)

    print("---", file = f)
    print("title: %s" % title, file = f)
    print("date: %s" % datetime.datetime.now(), file = f)
    print("---", file = f)
    print("\n\n", file = f)

def noop(x):
    return x

def gen_md_tbl_figs(args, col_names, fea, header, f, trans_fn = noop):
    # generate header row
    if header:
        l1, l2 = "|", "|"
        for col_name in col_names:
            l1 = l1 + " **" + col_name + "** | "
            l2 = l2 + " ---: | "
        print(l1, file = f)
        print(l2, file = f)

    # figures
    l = "|"
    for col_name in col_names:
        fig_name = get_outfile_name(args, fea + trans_fn(col_name), "svg")
        afil, rfil = get_res_path(args, fig_name)
        img = "![](" + rfil + ")"
        l = l + " " + img + " | "
    print(l, file = f)
    print("\n\n", file = f)

def gen_task_idle_stat_report(args, results, md_f):
    # configs
    gen_md_title("%s" % args.log, md_f)

    print("### Task statistics\n\n", file = md_f)

    # links to raw data
    print("- [task stats data](%s)" % 
          get_outfile_name(args, "task_stat", "csv"), file = md_f)
    print("- [idle stats data](%s)" % 
          get_outfile_name(args, "idle_stat", "csv"), file = md_f)
    print("\n\n", file = md_f)

    # figs table
    gen_md_tbl_figs(args, results.task_stat_names[1:-4], "task_dist_", True, md_f)

def gen_task_idle_stat(args, results, md_f):
    stat_names = results.task_stat_names
    task_stats = results.task_stats
    idle_stats = results.idle_stats
    stat_formats = results.task_stat_formats

    # generate CSV data
    ofname = get_outfile_name(args, "task_stat", "csv")
    with open(ofname, "w") as f:
        gen_stat_in_csv(stat_names, stat_formats, task_stats, f)

    ofname = get_outfile_name(args, "idle_stat", "csv")
    with open(ofname, "w") as f:
        gen_stat_in_csv(stat_names, stat_formats, idle_stats, f)

    # generate distribution graphs 
    plot_task_dist_figs(args, stat_names, task_stats)

    # generate markdown
    gen_task_idle_stat_report(args, results, md_f)

def gen_task_stat_corr(args, results, md_f):
    # generate correlation graphs
    plot_corr_figs(args, results.corrs, "task_stat_corr")

    # generate markdown
    print("### Pearson correlation between task features\n\n", file = md_f)
    fig_name = get_outfile_name(args, "task_stat_corr", "svg")
    afil, rfil = get_res_path(args, fig_name)
    print("![](" + rfil + ")", file = md_f)
    print("\n\n", file = md_f)


def get_fssafe_task_name(task_name):
    # NOTE: urlsafe_base64 encoding would be safer 
    # but it is hard to know what it is.
    non_safe_chars = [" ", "\t", "\\", "/", "[", "]", "{", "}", "&", 
                      ":", "\n", "\"", "'", "$"]
    for c in non_safe_chars:
        task_name = task_name.replace(c, "_")
    return task_name

def gen_task_stat_over_time(args, results, md_f):
    def get_index_stat_fea(results, fea_name):
        for i, name in enumerate(results.task_stat_names):
            if name == fea_name:
                return i
        return -1

    # generate tsov graphs for all tasks
    task_names = []
    ti = get_index_stat_fea(results, "task_name")
    for ts_r in results.task_stats:
        task_name = ts_r[ti]
        task_name_fssafe = get_fssafe_task_name(task_name)
        task = ev_task.find(task_name)
        task_color = task.color
        task_stat = task.task_stat
        task_names.append(task_name)
        plot_per_task_stat_over_time(args, task_stat, task_name_fssafe, 
                                     "tsov_" + task_name_fssafe)

    # intergrate the results into the report
    print("### Task's wait_time, sched_delay, and runtimes\n\n", file = md_f)
    for i in range(0, len(task_names), 10):
        gen_md_tbl_figs(args, task_names[i:i+10], "tsov_", True, 
                        md_f, trans_fn = get_fssafe_task_name)
        print("\n\n", file = md_f)
    print("\n\n", file = md_f)

def gen_callstack_stat(args, results, md_f):
    # generate CSV data for raw callstacks
    stat_names = results.cs_stat_names
    stat_formats = results.cs_stat_formats
    stats = results.cs_stats
    ofname = get_outfile_name(args, "callstack_stat", "csv")
    with open(ofname, "w") as f:
        gen_stat_in_csv(stat_names, stat_formats, stats, f)

    # generate CSV data for callstack types
    stat_names = results.cst_stat_names
    stat_formats = results.cst_stat_formats
    stats = results.cst_stats
    ofname = get_outfile_name(args, "callstack_type_stat", "csv")
    with open(ofname, "w") as f:
        gen_stat_in_csv(stat_names, stat_formats, stats, f)

    # plot callstack types
    trans_stats = list(zip(*stats))
    name_list = trans_stats[0]
    cnt_list = trans_stats[1]
    plot_pie_chart(args, name_list, cnt_list, "callstack_type_stat")

    # generate markdown
    print("### Callstacks tiggered scheduling\n\n", file = md_f)
    ofname = get_outfile_name(args, "callstack_stat", "csv")
    afil, rfil = get_res_path(args, ofname)
    print("- [callstacks](" + rfil + ")", file = md_f)

    ofname = get_outfile_name(args, "callstack_type_stat", "csv")
    afil, rfil = get_res_path(args, ofname)
    print("- [callstack types](" + rfil + ")", file = md_f)
    print("\n\n", file = md_f)

    ofname = get_outfile_name(args, "callstack_type_stat", "svg")
    afil, rfil = get_res_path(args, ofname)
    print("![](" + rfil + ")", file = md_f)
    print("\n\n", file = md_f)

def get_stat(key, stat_names, stat_cols):
    for stat_name, stat in zip(stat_names, stat_cols):
        if stat_name == key:
            return stat
    return None

def analyze_stats_correlation(args, results):
    # list of stat-pairs
    results.corrs = [
            # Q. How userful is num_sched in predicting task's behavior?
            pearson_corr("num_sched", "num_mig", "task_name"), 
            pearson_corr("num_sched", "runtime_avg", "task_name"), 
            #
            # Q. How useful is the vruntime in predicting task's behavior?
            pearson_corr("runtime_total", "num_sched", "task_name"),
            pearson_corr("runtime_total", "runtime_avg", "task_name"),
            # 
            # Q. Is task's runtime stable?
            pearson_corr("runtime_avg", "runtime_aad", "task_name"), 
            #
            # Q. Is task's wait time an useful indicator for something?
            pearson_corr("num_sched", "wait_time_total", "task_name"), 
            pearson_corr("runtime_avg", "wait_time_total", "task_name"), 
            pearson_corr("num_sched", "wait_time_avg", "task_name"), 
            pearson_corr("runtime_avg", "wait_time_avg", "task_name"), 
            pearson_corr("wait_time_avg", "wait_time_aad", "task_name"), 
            #
            # Q. Can we predict scheding dealy?
            pearson_corr("num_sched", "sched_delay_avg", "task_name"),
            pearson_corr("runtime_avg", "sched_delay_avg", "task_name"),
            pearson_corr("runtime_total", "sched_delay_avg", "task_name"),
            ]

    # calc pearson correlations
    stat_cols = transpose_2d_list(results.task_stats)
    for corr in results.corrs:
        corr.x_data = get_stat(corr.x_label, results.task_stat_names, stat_cols)
        corr.y_data = get_stat(corr.y_label, results.task_stat_names, stat_cols)
        corr.data_names = get_stat(corr.data_label, results.task_stat_names, stat_cols)
        corr.pcc = np.corrcoef(np.array(corr.x_data), np.array(corr.y_data))

def analyze_callstack(args, r):
    ev_callstack.analyze_stat()

    # collect call stack information
    stat_names = ["callstack", "num_sched", "num_task_scheduled_out"]
    stat_formats = ["{0:^50}"] + ["{0:>14}"] * (len(stat_names) - 1)
    stats = []
    for k, cs in ev_callstack.cs_dict.items():
        s = cs.callstack_stat
        stats.append( (str(cs), s.num_sched_events, s.num_ctask) )

    # sort by the number of events
    stats.sort(reverse = True, key = lambda x: x[1])

    # return the results
    r.cs_stat_names = stat_names
    r.cs_stat_formats = stat_formats
    r.cs_stats = stats

def analyze_callstack_type(args, r):
    # aggregate cs state results with the same cs type
    stat_names = ["callstack_type", "num_sched", "num_task_scheduled_out"]
    stat_formats = ["{0:^50}"] + ["{0:>14}"] * (len(stat_names) - 1)
    stats = []

    for k, cst in ev_callstack.cst_dict.items():
        ctask_set = set()
        num_sched_events = 0
        for cs in cst:
            ctask_set = ctask_set.union(cs.cs_ctasks)
            num_sched_events = num_sched_events + cs.callstack_stat.num_sched_events
        num_ctask = len(ctask_set)
        stats.append( (k, num_sched_events, num_ctask) )

    # sort by the number of events
    stats.sort(reverse = True, key = lambda x: x[1])

    # return the results
    r.cst_stat_names = stat_names
    r.cst_stat_formats = stat_formats
    r.cst_stats = stats

def analyze_events(args, events):
    r = analysis_results()

    analyze_task_idle_stat(args, r)
    analyze_stats_correlation(args, r)
    analyze_callstack(args, r)
    analyze_callstack_type(args, r)

    return r

def get_cmd_options(argv):
    parser = argparse.ArgumentParser(
            prog = "schedinsight",
            description = "Report the detailed analysis of scheduliing activities collected by `perf sched record`",)
    parser.add_argument('-o', '--outdir', action='store', required=True,
                        help='output directory') 
    parser.add_argument('-l', '--log', action='store', required=True,
                        help='log file prefix') 
    parser.add_argument('-q', '--quiet', action='store_true',
                        help='do not print result to stdout' ) 
    parser.add_argument('-p', '--pickle', action='store_true',
                        help='use pickle whenever possible' ) 
    parser.add_argument('-s', '--minsched', action='store', type=int, default=100,
                        help='set the minimum number of schedules for task analysis' ) 
    args = parser.parse_args(argv)
    return args

if __name__ == "__main__":
    # extend recursion limit for huge logs
    sys.setrecursionlimit(100000)

    # get options
    args = get_cmd_options(sys.argv[1:])

    # load and analyze the log
    events = load_schedmon_timehist(args)
    results = analyze_events(args, events)

    # generate a report in markdow
    md_fname = get_outfile_name(args, "report", "md")
    with open(md_fname, "w") as md_f:
        gen_task_idle_stat(args, results, md_f)
        gen_task_stat_corr(args, results, md_f)
        gen_task_stat_over_time(args, results, md_f)
        gen_callstack_stat(args, results, md_f)

    # convert the markdown to html
    html_fname = get_outfile_name(args, "report", "html")
    cmd = "pandoc --standalone --toc %s -o %s" % (md_fname, html_fname)
    p = subprocess.Popen(cmd, shell=True, stdout=None, stderr=None)
    p.wait()

    """
    plot_event_chart(args, "test", events)
    events = filter_sched_events(events, lambda e, d: e.ty == ev_type.IDLE, None)
    for time, ev in events.items():
        print(ev)
    """

