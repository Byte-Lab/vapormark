#!/usr/bin/env python3
import os
import sys
import argparse
import csv
import zlib
import collections
import statistics
import datetime
import subprocess
import pickle
import numpy as np
import matplotlib.pyplot as plt

def hash_rgb_from_str(s):
    h = zlib.crc32( bytes(s, 'utf-8') )
    r = (h & 0x00FF00) >> 8
    g = (h & 0xFF0000) >> 16
    b = (h & 0x0000FF) >> 0
    return (float(r)/0xFF, float(g)/0xFF, float(b)/0xFF)

def median(l):
    if len(l) == 0:
        return 0.0
    return statistics.median(l)

def average(l):
    if len(l) == 0:
        return 0.0
    return statistics.mean(l)

def aad(l, avg):
    # average absolute deviation: https://en.wikipedia.org/wiki/Average_absolute_deviation
    if len(l) == 0:
        return 0.0
    sum = 0.0
    for v in l:
        sum = sum + abs(avg - v)
    return sum / len(l)

class ev_type:
    SCHED = 0
    IDLE  = 1
    MIG   = 2
    AWAKE = 3

class ev_time:
    time   = 0.0 
    cpu_id = 0

    def __init__(self, t, c):
        self.time = t
        self.cpu_id = c

    def __repr__(self):
        return "\t".join(["%.6f" % self.time, "[%d]" % self.cpu_id])

class task_stat:
    # task
    ev_task = None

    # ev_sched or ev_idle stat
    sched_num = 0

    sched_waits = None
    sched_wait_med = 0.0
    sched_wait_avg = 0.0
    sched_wait_aad = 0.0
    sched_wait_sum = 0.0

    sched_delays = None
    sched_delay_med = 0.0
    sched_delay_avg = 0.0
    sched_delay_aad = 0.0
    sched_delay_sum = 0.0

    sched_runs = None
    sched_run_med = 0.0
    sched_run_avg = 0.0
    sched_run_aad = 0.0
    sched_run_sum = 0.0
    # TODO: sched_ideal_runs = []

    # ev_mig stat
    migrated_num = 0

    # TODO: sched reason
    # - iowait
    # - lock_wait
    # - preemption timeout
    # - poll/epoll
    # - pipe read

    def __init__(self, ev_task):
        self.ev_task = ev_task
        self.sched_num = 0
        self.sched_waits = []
        self.sched_wait_med = 0.0
        self.sched_wait_avg = 0.0
        self.sched_wait_aad = 0.0
        self.sched_wait_sum = 0.0

        self.sched_delays = []
        self.sched_delay_med = 0.0
        self.sched_delay_avg = 0.0
        self.sched_delay_aad = 0.0
        self.sched_delay_sum = 0.0

        self.sched_runs = []
        self.sched_run_med = 0.0
        self.sched_run_avg = 0.0
        self.sched_run_aad = 0.0
        self.sched_run_sum = 0.0

        self.migrated_num = 0

    def analyze_stat(self):
        # ev_sched or ev_idle?
        if self.ev_task.is_idle() == True:
            sched_events = self.ev_task.ctask_ty_events.get(ev_type.IDLE, collections.OrderedDict()) 
        else:
            sched_events = self.ev_task.ctask_ty_events.get(ev_type.SCHED, collections.OrderedDict())

        for time, ev in sched_events.items():
            self.sched_waits.append(ev.period.wait_time)
            self.sched_delays.append(ev.period.sch_delay)
            self.sched_runs.append(ev.period.run_time)

        # ev_sched/ev_idle stat
        self.sched_num = len(sched_events)

        self.sched_wait_med = median(self.sched_waits)
        self.sched_wait_avg = average(self.sched_waits)
        self.sched_wait_aad = aad(self.sched_waits, self.sched_wait_avg)
        self.sched_wait_sum = sum(self.sched_waits)

        self.sched_delay_med = median(self.sched_delays)
        self.sched_delay_avg = average(self.sched_delays)
        self.sched_delay_aad = aad(self.sched_delays, self.sched_delay_avg)
        self.sched_delay_sum = sum(self.sched_delays)

        self.sched_run_med = median(self.sched_runs)
        self.sched_run_avg = average(self.sched_runs)
        self.sched_run_aad = aad(self.sched_runs, self.sched_run_avg)
        self.sched_run_sum = sum(self.sched_runs)

        # ev_mig stat
        migrated_events = self.ev_task.ctask_ty_events.get(ev_type.MIG, collections.OrderedDict()) 
        self.migrated_num = len(migrated_events)

  
class ev_task:
    # per-class variables
    task_dict = {} 
    idle_task_name = "<idle>[0/0]"

    # per-instanace variables
    task_name = ""
    task_id   = 0
    parent_id = 0
    color = (0.0, 0.0, 0.0)

    # task indexes to events
    ctask_ty_events = None  # cur_task:ty  -> [events]
    ctask_cs_events = None  # cur_task:cs  -> [events]
    ntask_ty_events = None  # next_task:ty -> [events]

    # task stat
    task_stat = None

    def __init__(self, tname, tid, pid):
        self.task_name = tname
        self.task_id = tid
        self.parent_id = pid
        self.color = hash_rgb_from_str( str(self) )

        self.ctask_ty_events = collections.OrderedDict()
        self.ctask_cs_events = collections.OrderedDict()
        self.ntask_ty_events = collections.OrderedDict()

        self.task_stat = task_stat(self)

    def __repr__(self):
        return "%s[%d/%d]" % (self.task_name, self.task_id, self.parent_id)

    @classmethod
    def get_instance(cls, tname, tid, pid):
        key = "%s[%d/%d]" % (tname, tid, pid)
        inst = cls.task_dict.get(key)
        if inst == None: 
            inst = cls(tname, tid, pid)
            cls.task_dict[key] = inst
        return inst

    @classmethod
    def analyze_stat(cls):
        for k, t in cls.task_dict.items():
            t.task_stat.analyze_stat()

    def is_idle(self):
        if self.task_id == 0 and self.parent_id == 0 and self.task_name == "<idle>":
            return True
        return False

    def link_ctask(self, ev, cs = None):
        # - cur_task:ty -> [events]
        ty_events = self.ctask_ty_events.get(ev.ty)
        if ty_events == None:
            ty_events = self.ctask_ty_events[ev.ty] = collections.OrderedDict()
        ty_events[ev.time.time] = ev
        # - cur_task:cs -> [events]
        cs_events = self.ctask_cs_events.get(cs)
        if cs_events == None:
            cs_events = self.ctask_cs_events[cs] = collections.OrderedDict()
        cs_events[ev.time.time] = ev
        # - cs -> [ctasks]
        if cs != None:
            cs.link_ctask(self)

    def link_ntask(self, ev):
        # - next_task:ty -> [events]
        ty_events = self.ntask_ty_events.get(ev.ty)
        if ty_events == None:
            ty_events = self.ntask_ty_events[ev.ty] = collections.OrderedDict()
        self.ntask_ty_events[ev.time.time] = ev

class ev_period:
    wait_time = 0.0
    sch_delay = 0.0
    run_time  = 0.0

    def __init__(self, w, s, r):
        self.wait_time = w
        self.sch_delay = s
        self.run_time  = r

    def __repr__(self):
        return "\t".join(["%.3f" % self.wait_time, 
                          "%.3f" % self.sch_delay,
                          "%.3f" % self.run_time])
class ev_callstack:
    # per-class variables
    stackframe_dict= {} 

    # per-instanace variables
    stackframe = ""
    color = (0.0, 0.0, 0.0)

    # callstack to caller tasks
    cs_ctasks = None

    @classmethod
    def get_instance(cls, cs):
        inst = cls.stackframe_dict.get(cs)
        if inst == None: 
            inst = cls(cs)
            cls.stackframe_dict[cs] = inst
        return inst

    def link_ctask(self, ctask):
        self.cs_ctasks.add(ctask)

    def __init__(self, cs):
        self.stackframe = cs
        self.color = hash_rgb_from_str( str(self) )
        self.cs_ctasks = set()

    def __repr__(self):
        return self.stackframe

class ev_sched:
    # per-class variables
    ty = ev_type.SCHED
    color =  hash_rgb_from_str( str(ev_type.SCHED) )

    # per-instanace variables
    time   = None
    period = None
    cur_task  = None
    next_task = None 
    callstack = None

    def __init__(self, time, period, cur_task, next_task, callstack):
        self.time = time
        self.period = period

        self.cur_task = cur_task
        self.callstack = callstack
        self.next_task = next_task

        self.cur_task.link_ctask(self, self.callstack)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["S", str(self.time), str(self.cur_task), str(self.period), 
                          "=>", str(self.next_task), str(self.callstack)])

class ev_idle:
    # per-class variables
    ty = ev_type.IDLE
    color =  hash_rgb_from_str( str(ev_type.IDLE) )

    # per-instanace variables
    time = None
    period = None
    cur_task  = None
    next_task = None 

    def __init__(self, time, period, cur_task, next_task):
        self.time = time
        self.period = period

        self.cur_task = cur_task
        self.next_task = next_task

        self.cur_task.link_ctask(self)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["I", str(self.time), str(self.cur_task), str(self.period), 
                          "=>", str(self.next_task)])

class ev_mig:
    # per-class variables
    ty = ev_type.MIG
    color =  hash_rgb_from_str( str(ev_type.MIG) )

    # per-instanace variables
    time   = None
    cur_task  = None
    next_task = None 
    to_cpu_id = 0

    def __init__(self, time, cur_task, migrated_task, to_cpu_id):
        self.time = time
        self.to_cpu_id = to_cpu_id

        self.cur_task = migrated_task # migrated task should be the key
        self.next_task = cur_task     # next task is indeed an initiator

        self.cur_task.link_ctask(self)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["M", str(self.time), str(self.cur_task), 
                          "=>", str(self.next_task)])

class ev_awake:
    # per-class variables
    ty = ev_type.AWAKE
    color =  hash_rgb_from_str( str(ev_type.AWAKE) )

    # per-instanace variables
    time   = None
    cur_task  = None
    next_task = None 

    def __init__(self, time, cur_task, awakened_task):
        self.time = time

        self.cur_task = awakened_task # awakened task should be the key
        self.next_task = cur_task     # next task is indeed an initiator

        self.cur_task.link_ctask(self)
        self.next_task.link_ntask(self)

    def __repr__(self):
        return "\t".join(["A", str(self.time), str(self.cur_task), 
                          "=>", str(self.next_task)])

class pearson_corr:
    x_label = ""
    y_label = ""
    data_label = ""
    x_data  = None
    y_data  = None
    data_names = None
    pcc     = None

    def __init__(self, x, y, d):
        self.x_label = x
        self.y_label = y
        self.data_label = d
        self.x_data  = None
        self.y_data  = None
        self.data_names = None
        self.pcc     = None

class analysis_results:
    # task & idle status
    task_stat_names = None
    task_stats = None
    idle_stats = None
    task_stat_formats = None

    # pearson correlations
    corrs = None

    def __init__(self):
        task_stat_names = []
        task_stats = []
        idle_stats = []
        task_stat_formats = []
        corrs = []

class pickled_jar:
    task_dict = None
    stackframe_dict = None
    sched_events = None

    def __init__(self, se):
        self.task_dict = ev_task.task_dict
        self.stackframe_dict = ev_callstack.stackframe_dict
        self.sched_events = se

def parse_ev_time(toks):
    time = float(toks[0])
    cpu_id = int(toks[1][1:-1])
    return ev_time(time, cpu_id), toks[2:]
    
def parse_ev_type(toks):
    if toks[0] == "s":
        return ev_type.SCHED, toks[1:]
    elif toks[0] == "i":
        return ev_type.IDLE, toks[1:]
    elif toks[0] == "m":
        return ev_type.MIG, toks[1:]
    else:
        return ev_type.AWAKE, toks

def parse_ev_task(toks):
    if toks[0] == "<idle>" or toks[0] == "swapper": 
        return ev_task.get_instance(toks[0], 0, 0), toks[1:]
    
    tstr = ""
    for i, t in enumerate(toks):
        if t[-1] == "]":
            tstr = tstr + t
            toks = toks[i+1:]
            break
        tstr = tstr + t + " "

    tsk_tok = tstr[:-1].split("[")
    tname = tsk_tok[0]
    tid, pid = 0, 0
    if len(tsk_tok) == 2:
        pid_tok = tsk_tok[1].split("/")
        tid = int(pid_tok[0])
        if len(pid_tok) == 2: 
            pid = int(pid_tok[1])
    return ev_task.get_instance(tname, tid, pid), toks

def parse_ev_period(toks):
    w = float(toks[0])
    s = float(toks[1])
    r = float(toks[2])
    return ev_period(w, s, r), toks[3:]

def parse_ev_callstack(toks):
    stackframe = ' '.join(toks)
    return ev_callstack.get_instance(stackframe), []

def parse_ev_sched(toks, time):
    cur_task, toks = parse_ev_task(toks)
    period, toks = parse_ev_period(toks)
    next_task, toks = parse_ev_task(toks[1:]) # toks[0] should be 'next:'
    callstack, toks = parse_ev_callstack(toks)
    return ev_sched(time, period, cur_task, next_task, callstack)

def parse_ev_idle(toks, time):
    cur_task, toks = parse_ev_task(toks)
    period, toks = parse_ev_period(toks) 
    next_task, toks = parse_ev_task(toks[1:]) # toks[0] should be 'next:'
    return ev_idle(time, period, cur_task, next_task)

def parse_ev_mig(toks, time):
    cur_task, toks = parse_ev_task(toks)
    migrated_task, toks = parse_ev_task(toks[1:])  # toks[0] should be "migrated:"
    to_cpu_id = int(toks[3]) # toks[] = ["cpu", from_cpu_id, "=>", to_cpu_id]
    return ev_mig(time, cur_task, migrated_task, to_cpu_id)

def parse_ev_awake(toks, time):
    cur_task, toks = parse_ev_task(toks)
    awakened_task, toks = parse_ev_task(toks[1:])  # toks[0] should be "awakened:"
    return ev_awake(time, cur_task, awakened_task)

def parse_ev_line(line):
    parsers = {ev_type.SCHED: parse_ev_sched, ev_type.IDLE: parse_ev_idle, 
               ev_type.MIG: parse_ev_mig,     ev_type.AWAKE: parse_ev_awake,}

    toks = line.split()
    if len(toks) == 0:
        return None

    time, toks = parse_ev_time(toks)
    ty, toks = parse_ev_type(toks)
    return parsers[ty](toks, time)

def skip_column_header(f):
    f.readline()
    f.readline()
    f.readline()

def get_schedmon_log_name(args, kind):
    log = os.path.join(args.outdir,
                       args.log + "-schedmon-" + kind+ "__.log")
    return log

def parse_sched_events(f):
    # - header
    skip_column_header(f)

    # - scheduling events
    events = collections.OrderedDict()
    for line in f:
        ev = parse_ev_line(line)
        if ev == None:
            break
        events[ev.time.time] = ev
    return events

def is_newer(file_new, file_old):
    if os.path.isfile(file_new) == False:
        return False
    return os.path.getmtime(file_new) > os.path.getmtime(file_old)

def load_pickle(args, log_fil):
    if args.pickle == False:
        return None

    pickle_fil = get_outfile_name(args, "pickled_jar__", "pickle")
    if is_newer(pickle_fil, log_fil):
        with open(pickle_fil, mode="rb") as pf:
            pj = pickle.load(pf)
            # init class variables
            ev_task.task_dict = pj.task_dict
            ev_callstack.stackframe_dict = pj.stackframe_dict
            return pj.sched_events
    return None

def save_pickle(args, sched_events):
    if args.pickle == False:
        return

    pickle_fil = get_outfile_name(args, "pickled_jar__", "pickle")
    pj = pickled_jar(sched_events)
    with open(pickle_fil, mode="wb") as f:
        pickle.dump(pj, f)

def parse_schedmon_timehist(args):
    # get a log file name
    log_fil = get_schedmon_log_name(args, "timehist_full")
    if os.path.isfile(log_fil) == False:
        log_fil = get_schedmon_log_name(args, "timehist_short")

    # first try to load the pickled events
    sched_events = load_pickle(args, log_fil)
    if sched_events != None:
        print("bingo!") # FIXME TODO
        return  sched_events

    # if nothing pickled, parse the log and pickle it
    with open(log_fil, "r") as f:
        # try to load the pickled log first
        sched_events = load_pickle(args, log_fil)

        # parse and pickle the log
        if sched_events == None:
            sched_events = parse_sched_events(f)
            save_pickle(args, sched_events)
        # - TODO: Runtime summary
        # - TODO: Terminated tasks:
        # - TODO: Idle stats:
        # - TODO: Overall smmary
    return sched_events

def load_schedmon_timehist(args):
    return parse_schedmon_timehist(args)

def filter_sched_events(events, filter_fn, filter_data):
    filtered_events = collections.OrderedDict()

    for time, ev in events.items():
        if filter_fn(ev, filter_data) == True:
            filtered_events[time] = ev
    rebuild_indexes(filtered_events)

    return filtered_events

def is_meaningful_task(args, task_stat):
    # filter out statically meaningless tasks
    if task_stat.sched_num < args.minsched:
        return False
    # filter out never scheduled tasks
    if task_stat.sched_num == 0 and task_stat.migrated_num == 0:
        return False
    return True

def analyze_task_idle_stat(args):
    stat_names = ["task_name", "num_sched", "num_mig", # 0--2
                  "wait_time_med", "wait_time_avg",
                  "wait_time_aad", "wait_time_total", # 3--6
                  "sched_delay_med", "sched_delay_avg",
                  "sched_delay_aad", "sched_delay_total", # 7-10
                  "runtime_med", "runtime_avg",
                  "runtime_aad", "runtime_total", # 11-14
                  "rank_nsched", "rank_nmig", "rank_runtime", "score", # 15-18
                  ]

    # collect system-wide task stats
    task_stats = []
    idle_stats = []
    for k, t in ev_task.task_dict.items():
        s = t.task_stat

        # filter out statically meaningless tasks
        if is_meaningful_task(args, s) == False:
            continue

        t_info = [str(t), s.sched_num, s.migrated_num]
        w_stat = [s.sched_wait_med, s.sched_wait_avg, s.sched_wait_aad, s.sched_wait_sum]
        d_stat = [s.sched_delay_med, s.sched_delay_avg, s.sched_delay_aad, s.sched_delay_sum]
        r_stat = [s.sched_run_med, s.sched_run_avg, s.sched_run_aad, s.sched_run_sum]

        stat = t_info + w_stat + d_stat + r_stat

        if t.is_idle():
            idle_stats.append(stat + [0, 0, 0, 0])
        else:
            task_stats.append(stat)

    # calc score
    # - by number of sched
    task_stats.sort(reverse = True, key = lambda x: x[1])
    for i, s in enumerate(task_stats):
        s.append(i) # 15
    # - by number of migration
    task_stats.sort(reverse = True, key = lambda x: x[2])
    for i, s in enumerate(task_stats):
        s.append(i) # 16
    # - by total runtime
    task_stats.sort(reverse = True, key = lambda x: x[14])
    for i, s in enumerate(task_stats):
        s.append(i) # 17
    # - score
    for s in task_stats:
        ns, nm, rt = s[15], s[16], s[17]
        score = ns*ns + (rt*rt)/2 + (nm*nm)/8
        s.append(score) #18

    # soft by score
    task_stats.sort(key = lambda x: x[18])

    return (stat_names, task_stats, idle_stats)

def get_outfile_name(args, kind, suffix):
    ofname = os.path.join(args.outdir, args.log + 
                          "-schedinsight-" + kind + "." + suffix)
    return ofname

def reset_plot():
    plt.clf()
    plt.style.use('default')
    plt.rcParams['font.size'] = 7

def plot_event_chart(args, plot_name, events):
    ty_map = {}
    ctask_map = {}
    ntask_map = {}
    cs_map = {}

    # build data for plot
    def append_color(m, c, i):
        if m.get(c) == None:
            m[c] = []
        m[c].append(i)

    for i, (time, ev) in enumerate(events.items()):
        # - type
        append_color(ty_map, ev.color, i)
        append_color(ctask_map, ev.cur_task.color, i)
        append_color(ntask_map, ev.next_task.color, i)
        if ev.ty == ev_type.SCHED: 
            append_color(cs_map, ev.callstack.color, i)
        # TODO: not very useful if there are more than 1000 events
        # TODO: extend the inerface to time range

    # plot events
    # - prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=4, ncols=1, figsize=(7, 3.5), tight_layout=True)

    # - plot type
    def plot_map(ax, m, title):
        ax.tick_params(left = False, right = False , labelleft = False , 
                       labelbottom = False, bottom = False)
        for c, x_data in m.items():
            ax.bar(x_data, [1] * len(x_data), align='edge', width=1, color = c)
        ax.set_ylim(bottom = 0, top = 1)
        ax.set_ylabel(title)

    plot_map(axs[0], ty_map, "event type")
    plot_map(axs[1], ctask_map, "current task")
    plot_map(axs[2], cs_map, "callstack")
    plot_map(axs[3], ntask_map, "next task")

    # - decoration
    axs[0].tick_params(labeltop = True, top = True)
    axs[3].tick_params(labelbottom = True, bottom = True)
    plt.subplots_adjust(hspace = 0)

    # - save to the file
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)

def gen_stat_in_csv(col_names, col_formats, tuples, f):
    def get_sep(c, ncol):
        if c == (ncol - 1):
            return "\n"
        else:
            return ", "

    def is_float(n):
        try: 
            return int(n) != float(n)
        except ValueError:
            return False

    # column header
    ncol = len(col_names)
    for i, (fmt, cname) in enumerate(zip(col_formats, col_names)):
        print(fmt.format(cname), end=get_sep(i, ncol), file = f)

    # stat tuples 
    for tup in tuples: 
        for i, (fmt, cdata) in enumerate(zip(col_formats, tup)):
            if is_float(cdata):
                print(fmt.format("%.8f" % cdata), end=get_sep(i, ncol), file = f)
            else:
                print(fmt.format(cdata), end=get_sep(i, ncol), file = f)

def plot_dist_fig(args, plot_name, sorted_values, title, x_label, y_label):
    # prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(3, 8), tight_layout=True)

    # 1) violin plot
    # - plot
    ax = axs[0]
    violin = ax.violinplot([sorted_values], showmeans=True,  quantiles=[0.1, 0.5, 0.9])
    violin['bodies'][0].set_facecolor( hash_rgb_from_str(y_label) )
    violin['cmeans'].set_edgecolor('red')
    # - set title
    ax.set_title(title)
    # - decoration
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)

    # 2) distribution line plot
    # - plot
    ax = axs[1]
    ax.plot(range(len(sorted_values)), sorted_values, linewidth=1, color='black')
    # - decoration
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)

    # 3) histogram plot
    # - plot
    ax = axs[2]
    ax.hist(sorted_values, bins = 30)
    # - decoration
    max_hist = len(sorted_values)/3
    ax.set_ylim(bottom = 0, top = max_hist)
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)

    # - save to the file
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)

def plot_corr_figs(args, corrs, plot_name):
    # prepare canvas
    reset_plot()
    fig, axs = plt.subplots(nrows=1, ncols=len(corrs), 
                            figsize=(3*len(corrs), 3), tight_layout=True)

    # scatter plot
    for i, corr in enumerate(corrs):
        ax = axs[i]
        colors = []
        for name in corr.data_names:
            colors.append( hash_rgb_from_str(name) )
        ax.scatter(corr.x_data, corr.y_data, c=colors, marker="x")
        ax.set(xlabel=corr.x_label, ylabel=corr.y_label)
        ax.title.set_text("Correlation = " + "{:.2f}".format(corr.pcc[0,1]))

    # - save to the file
    fig_name = get_outfile_name(args, plot_name, "svg")
    plt.savefig(fig_name)

def transpose_2d_list(ll):
    return list(zip(*ll))

def plot_task_dist_figs(args, stat_names, task_stats):
    stat_cols = transpose_2d_list(task_stats)
    for name, stat in zip(stat_names[1:-4], stat_cols[1:-4]):
        plot_dist_fig(args, "task_dist_" + name, sorted(stat), name, "", "")

def get_res_path(args, fname):
    afil = os.path.join(args.outdir, fname)
    rfil = os.path.relpath(afil, start = args.outdir)
    return afil, rfil

def gen_md_title(title, f):
    print("``` {=html}", file = f)
    print("<style>", file = f)
    print("body { min-width: 80% !important; }", file = f)
    print("</style>", file = f)
    print("```", file = f)

    print("---", file = f)
    print("title: %s" % title, file = f)
    print("date: %s" % datetime.datetime.now(), file = f)
    print("---", file = f)
    print("\n\n", file = f)

def gen_md_tbl_figs(args, col_names, fea, header, f):
    # generate header row
    if header:
        l1, l2 = "|", "|"
        for col_name in col_names:
            l1 = l1 + " **" + col_name + "** | "
            l2 = l2 + " ---: | "
        print(l1, file = f)
        print(l2, file = f)

    # figures
    l = "|"
    for col_name in col_names:
        fig_name = get_outfile_name(args, fea + col_name, "svg")
        afil, rfil = get_res_path(args, fig_name)
        img = "![](" + rfil + ")"
        l = l + " " + img + " | "
    print(l, file = f)
    print("\n\n", file = f)

def gen_task_idle_stat_report(args, results, md_f):
    # configs
    gen_md_title("%s" % args.log, md_f)

    print("### Task statistics\n\n", file = md_f)

    # links to raw data
    print("- [task stats data](%s)" % 
          get_outfile_name(args, "task_stat", "csv"), file = md_f)
    print("- [idle stats data](%s)" % 
          get_outfile_name(args, "idle_stat", "csv"), file = md_f)
    print("\n\n", file = md_f)

    # figs table
    gen_md_tbl_figs(args, results.task_stat_names[1:-4], "task_dist_", True, md_f)

def gen_task_idle_stat(args, results, md_f):
    stat_names = results.task_stat_names
    task_stats = results.task_stats
    idle_stats = results.idle_stats
    stat_formats = results.task_stat_formats

    # generate CSV data
    ofname = get_outfile_name(args, "task_stat", "csv")
    with open(ofname, "w") as f:
        gen_stat_in_csv(stat_names, stat_formats, task_stats, f)

    ofname = get_outfile_name(args, "idle_stat", "csv")
    with open(ofname, "w") as f:
        gen_stat_in_csv(stat_names, stat_formats, idle_stats, f)

    # generate distribution graphs 
    plot_task_dist_figs(args, stat_names, task_stats)

    # generate markdown
    gen_task_idle_stat_report(args, results, md_f)

def gen_task_stat_corr(args, results, md_f):
    # generate correlation graphs
    plot_corr_figs(args, results.corrs, "task_stat_corr")

    # generate markdown
    print("### Pearson correlation between task features\n\n", file = md_f)
    fig_name = get_outfile_name(args, "task_stat_corr", "svg")
    afil, rfil = get_res_path(args, fig_name)
    print("![](" + rfil + ")", file = md_f)
    print("\n\n", file = md_f)

def get_stat(key, stat_names, stat_cols):
    for stat_name, stat in zip(stat_names, stat_cols):
        if stat_name == key:
            return stat
    return None

def analyze_stats_correlation(args, results):
    # list of stat-pairs
    results.corrs = [
            # Q. How userful is num_sched in predicting task's behavior?
            pearson_corr("num_sched", "num_mig", "task_name"), 
            pearson_corr("num_sched", "runtime_avg", "task_name"), 
            #
            # Q. How useful is the vruntime in predicting task's behavior?
            pearson_corr("runtime_total", "num_sched", "task_name"),
            pearson_corr("runtime_total", "runtime_avg", "task_name"),
            # 
            # Q. Is task's runtime stable?
            pearson_corr("runtime_avg", "runtime_aad", "task_name"), 
            #
            # Q. Is task's wait time an useful indicator for something?
            pearson_corr("num_sched", "wait_time_avg", "task_name"), 
            pearson_corr("runtime_avg", "wait_time_avg", "task_name"), 
            pearson_corr("wait_time_avg", "wait_time_aad", "task_name"), 
            #
            # Q. Can we predict scheding dealy?
            pearson_corr("num_sched", "sched_delay_avg", "task_name"),
            pearson_corr("runtime_avg", "sched_delay_avg", "task_name"),
            pearson_corr("runtime_total", "sched_delay_avg", "task_name"),
            ]

    # calc pearson correlations
    stat_cols = transpose_2d_list(results.task_stats)
    for corr in results.corrs:
        corr.x_data = get_stat(corr.x_label, results.task_stat_names, stat_cols)
        corr.y_data = get_stat(corr.y_label, results.task_stat_names, stat_cols)
        corr.data_names = get_stat(corr.data_label, results.task_stat_names, stat_cols)
        corr.pcc = np.corrcoef(np.array(corr.x_data), np.array(corr.y_data))

def analyze_events(args, events):
    r = analysis_results()

    # build per-task stats 
    ev_task.analyze_stat()

    # analysis task & idle status
    r.task_stat_names, r.task_stats, r.idle_stats = analyze_task_idle_stat(args)
    r.task_stat_formats = ["{0:^30}"] + ["{0:>14}"] * (len(r.task_stat_names) - 1)

    # correlation analysis
    analyze_stats_correlation(args, r)

    return r

def get_cmd_options(argv):
    parser = argparse.ArgumentParser(
            prog = "schedinsight",
            description = "Report the detailed analysis of scheduliing activities collected by `perf sched record`",)
    parser.add_argument('-o', '--outdir', action='store', required=True,
                        help='output directory') 
    parser.add_argument('-l', '--log', action='store', required=True,
                        help='log file prefix') 
    parser.add_argument('-q', '--quiet', action='store_true',
                        help='do not print result to stdout' ) 
    parser.add_argument('-p', '--pickle', action='store_true',
                        help='use pickle whenever possible' ) 
    parser.add_argument('-s', '--minsched', action='store', type=int, default=100,
                        help='set the minimum number of schedules for task analysis' ) 
    args = parser.parse_args(argv)
    return args

if __name__ == "__main__":
    # extend recursion limit for huge logs
    sys.setrecursionlimit(100000)

    # get options
    args = get_cmd_options(sys.argv[1:])

    # load and analyze the log
    events = load_schedmon_timehist(args)
    results = analyze_events(args, events)

    # generate a report in markdow
    md_fname = get_outfile_name(args, "report", "md")
    with open(md_fname, "w") as md_f:
        gen_task_idle_stat(args, results, md_f)
        gen_task_stat_corr(args, results, md_f)

    # convert the markdown to html
    html_fname = get_outfile_name(args, "report", "html")
    cmd = "pandoc --standalone --toc %s -o %s" % (md_fname, html_fname)
    p = subprocess.Popen(cmd, shell=True, stdout=None, stderr=None)
    p.wait()

    """
    for cs in ev_callstack.stackframe_dict:
        print(cs)

    plot_event_chart(args, "test", events)
    events = filter_sched_events(events, lambda e, d: e.ty == ev_type.IDLE, None)
    for time, ev in events.items():
        print(ev)
    """

